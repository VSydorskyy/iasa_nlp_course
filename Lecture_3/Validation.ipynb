{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agenda\n",
    "1. [What is validation and why do we need it?](#Intro)\n",
    "2. [Evaluation Metrics:](#metrics) <br>\n",
    "    2.1 [Optimization Loss and Evaluation Metrics](#loss_and_metric) <br>\n",
    "    2.2 [Classification metrics](#classification_metrics) <br>\n",
    "    2.3 [Regression metrics](#regression_metrics) <br>\n",
    "    2.4 [Embedding metrics](#embedding_metrics) <br>\n",
    "    2.5 [Generative NLP metrics](#generative_metrics) <br>\n",
    "3. [Validation Strategies:](#validation_strategies) <br>\n",
    "    3.1 [Overfitting. Why do we need train/test concept?](#overfitting) <br>\n",
    "    3.2 [Holdout / Stratified split / train-validation-test](#holdout) <br>\n",
    "    3.3 [K-fold / Stratified K-fold / Repeated K-fold](#kfold) <br>\n",
    "    3.4 [Time-based validation / Time K-fold](#timebased) <br>\n",
    "    3.5 [Group K-fold](#groupkfold) <br>\n",
    "4. [Local validation VS real-life/competition testing metrics mismatch](#validation_mismatch) <br>\n",
    "    4.1 [Wrong local validation strategy](#wrong_local_validation) <br>\n",
    "    4.2 [Shifted features distributions](#shifted_features) <br>\n",
    "    4.3 [Adversarial validation](#adversarial_validation) <br>\n",
    "5. [Homework](#Homework)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Intro'></a>\n",
    "# What is validation and why do we need it?\n",
    "\n",
    "The ML models validation process is a crucial step in developing machine learning models. It involves assessing the performance and generalization capabilities of a trained model to ensure that it can make accurate predictions on new, unseen data. There are such key points in evaluating models:\n",
    "\n",
    "**Generalization performance** - We want to estimate the predictive performance of our model on future (unseen) data.\n",
    "- Ideally, the estimated performance (based on evaluation metrics) of a model tells us how well it performs on unseen data, because making predictions on future (unseen) data is often the main problem we want to solve.\n",
    "\n",
    "**Hyperparameters tuning and feature engineering** - We want to increase the predictive performance by tweaking the learning algorithm and selecting the best performing model from a given hypothesis space.\n",
    "- Typically, machine learning involves a lot of experimentation. Running a learning algorithm over a training dataset with different hyperparameter settings and different features will result in different models. Since we are typically interested in selecting the best-performing model from this set, we need to find a way to estimate their respective performances in order to rank them against each other.\n",
    "\n",
    "**Model selection** - We want to compare different ML models (e.g. linear, decision tree, gradient boosting, etc.), selecting the best-performing one.\n",
    "- We are usually not only experimenting with the one single algorithm that we think would be the “best solution” under the given circumstances. More often than not, we want to compare different models to each other, oftentimes in terms of predictive and computational performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='metrics'></a>\n",
    "# 2. Evaluation metrics\n",
    "An evaluation metric, in the context of machine learning and data analysis, is a quantitative measure used to assess the performance or quality of a model or a system's output with respect to a specific task or objective. Evaluation metrics are crucial because they provide a standardized way to measure and compare the performance of different models or systems. The choice of evaluation metric depends on the nature of the task being addressed (e.g. classification, regression, ranking) and the specific goals and requirements of the project.\n",
    "\n",
    "<a id='loss_and_metric'></a>\n",
    "## 2.1 Optimization Loss and Evaluation Metrics\n",
    "Optimization loss and evaluation metrics serve different roles in the context of machine learning model training and evaluation. Here are the key differences between the two: <br>\n",
    "1. **Purpose**: <br>\n",
    "    **Optimization Loss:** often simply referred to as \"loss,\" is a mathematical function that the machine learning model aims to minimize during training. It serves as the objective function that guides the model's parameter updates during optimization. The primary purpose of the loss function is to measure the dissimilarity between the model's predictions and the true target values. It provides the model with a signal for adjusting its internal parameters to improve its predictive performance on the training data. The model's parameters are updated in the direction that reduces this loss, using techniques like gradient descent.<br>\n",
    "    **Evaluation Metric:** used to assess the model's performance and quality after it has been trained and to evaluate how well it generalizes to new, unseen data. These metrics are not used during training but rather during the model evaluation phase to provide a quantitative measure of how well the model is achieving its intended task. Evaluation metrics are often chosen based on the specific problem and the practical goals of the application.\n",
    "    \n",
    "2. **Function properties:** <br>\n",
    "    **Optimization Loss:** differentiable \"almost everywhere\" with respect to model parameters function that is well-suited for gradient-based optimization algorithms. Common examples include mean squared error (MSE), mean absolute error (MAE) for regression tasks and cross-entropy loss for classification tasks. <br>\n",
    "    **Evaluation Metric:** both continuous and discrete, are usually much better interpretable than loss, depending on the nature of the task. Examples include accuracy, precision, recall, F1-score, roc-auc, mean absolute percentage error, etc.\n",
    "    \n",
    "<a id='classification_metrics'></a>\n",
    "## 2.2 Classification metrics\n",
    "\n",
    "A binary machine learning classification task is a type of supervised learning problem in which the goal is to categorize data points into one of two distinct classes or categories. In other words, the output or prediction of the model is the probability distribution of an element belonging to the corresponding classes. These two classes are often referred to as the positive class and the negative class. The objective is to learn a model that can accurately classify new, unseen data points into one of these two classes based on the features or attributes of the data.\n",
    "\n",
    "Let's take a look at some common metrics using NLP example [Disaster Tweets](https://www.kaggle.com/competitions/nlp-getting-started):\n",
    "![](https://storage.googleapis.com/kaggle-media/competitions/tweet_screenshot.png)\n",
    "\n",
    "The author explicitly uses the word “ABLAZE” (палаючий) but means it metaphorically. This is clear to a human right away, especially with the visual aid. But it’s less clear to a machine.\n",
    "\n",
    "In this competition, you’re challenged to build a machine learning model that predicts which Tweets are about real disasters and which one’s aren’t. You’ll have access to a dataset of 10,000 tweets that were hand classified.\n",
    "Disclaimer: The dataset for this competition contains text that may be considered profane, vulgar, or offensive.\n",
    "\n",
    "**Please check info about Kaggle API** [here](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=&cad=rja&uact=8&ved=2ahUKEwifhoe5_7mBAxXPGRAIHXuXAWIQFnoECBIQAw&url=https%3A%2F%2Fgithub.com%2FKaggle%2Fkaggle-api%23%3A~%3Atext%3DTo%2520use%2520the%2520Kaggle%2520API%2Cfile%2520containing%2520your%2520API%2520credentials.&usg=AOvVaw1BewOUEPrUy1mWsrqk8T5U&opi=89978449)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading nlp-getting-started.zip to /Users/abazdyrev/JupyterNotebooks/iasa_nlp_course/Lecture_3\n",
      "100%|████████████████████████████████████████| 593k/593k [00:00<00:00, 1.07MB/s]\n",
      "100%|████████████████████████████████████████| 593k/593k [00:00<00:00, 1.07MB/s]\n",
      "Archive:  nlp-getting-started.zip\n",
      "  inflating: nlp-getting-started/sample_submission.csv  \n",
      "  inflating: nlp-getting-started/test.csv  \n",
      "  inflating: nlp-getting-started/train.csv  \n"
     ]
    }
   ],
   "source": [
    "!kaggle competitions download -c nlp-getting-started\n",
    "!unzip nlp-getting-started.zip -d nlp-getting-started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1712</th>\n",
       "      <td>2468</td>\n",
       "      <td>collided</td>\n",
       "      <td>St. Joseph, Minnesota</td>\n",
       "      <td>Two trains have collided in India. Please pray...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7201</th>\n",
       "      <td>10316</td>\n",
       "      <td>weapon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>only weapon im scared off is karma</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>731</th>\n",
       "      <td>1057</td>\n",
       "      <td>bleeding</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I've been bleeding in your silence \\nI feel sa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5884</th>\n",
       "      <td>8404</td>\n",
       "      <td>sandstorm</td>\n",
       "      <td>USA</td>\n",
       "      <td>Watch This Airport Get Swallowed Up By A Sands...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>970</th>\n",
       "      <td>1405</td>\n",
       "      <td>body%20bag</td>\n",
       "      <td>NaN</td>\n",
       "      <td>new summer long thin body bag hip A word skirt...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id     keyword               location  \\\n",
       "1712   2468    collided  St. Joseph, Minnesota   \n",
       "7201  10316      weapon                    NaN   \n",
       "731    1057    bleeding                    NaN   \n",
       "5884   8404   sandstorm                    USA   \n",
       "970    1405  body%20bag                    NaN   \n",
       "\n",
       "                                                   text  target  \n",
       "1712  Two trains have collided in India. Please pray...       1  \n",
       "7201                 only weapon im scared off is karma       0  \n",
       "731   I've been bleeding in your silence \\nI feel sa...       0  \n",
       "5884  Watch This Airport Get Swallowed Up By A Sands...       1  \n",
       "970   new summer long thin body bag hip A word skirt...       0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "df_twitter = pd.read_csv('nlp-getting-started/train.csv')\n",
    "df_twitter.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    0.57034\n",
       "1    0.42966\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1 - real disaster, 0 - metaphoric\n",
    "df_twitter.target.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#straightforward train/test split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df_twitter.text, df_twitter.target, test_size=0.3, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modeling and inference\n",
    "\n",
    "pipe_classification = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer(\n",
    "        analyzer='word',\n",
    "        stop_words='english',\n",
    "        ngram_range=(1, 3),\n",
    "        lowercase=True,\n",
    "        min_df=5,\n",
    "        max_features=30000\n",
    "    )),  \n",
    "    ('classifier', LogisticRegression(C=1.0, random_state=42))\n",
    "])\n",
    "\n",
    "pipe_classification.fit(X_train, y_train)\n",
    "\n",
    "y_hat = pipe_classification.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$Let \\hspace{0.1cm} Y = \\Bigl\\{ y_{i} \\Bigl\\} \\hspace{0.1cm} - \\hspace{0.1cm} vector \\hspace{0.1cm} of\\hspace{0.1cm} ground\\hspace{0.1cm} truth\\hspace{0.1cm} labels \\hspace{0.5cm}  y_{i} є \\{0, 1\\}$$\n",
    "$$Let \\hspace{0.1cm} \\hat{Y} = \\Bigl\\{ \\hat{y_{i}} \\Bigl\\} \\hspace{0.1cm} - \\hspace{0.1cm} vector \\hspace{0.1cm} of\\hspace{0.1cm} predicted\\hspace{0.1cm} probabilities\\hspace{0.1cm} of \\hspace{0.1cm} class \\hspace{0.1cm} 1 \\hspace{0.5cm} \\hat{y_{i}} є [0, 1]$$\n",
    "### Continuous metrics:\n",
    "**Log-Loss / Cross-Entropy Loss** <br>\n",
    "$$ LogLoss = {-\\frac{1}{N} \\sum_{i=1}^{N}(y_{i}log(\\hat{y_{i}})+(1-y_i)log(1-\\hat{y_{i}}))}$$\n",
    "##### Pros:\n",
    "    + Differentiable\n",
    "    + Could be a loss\n",
    "    + Impact of misclassification confidence: Log loss takes into account the model's confidence in its predictions. If a model is highly confident in an incorrect prediction, it will result in a higher log loss than a less confident incorrect prediction\n",
    "    + Multiclass extension: Log loss can be extended to multiclass classification problems, where there are more than two classes\n",
    "\n",
    "##### Cons:\n",
    "    - Poorly interpretable (especially for people without IT/ML background)\n",
    "    - Not limited: Log loss values range from 0 to positive infinity\n",
    "    - Doesn't have \"reference values\": without knowing the task and classes distribution it's hard to tell whether e.g. 0.1/0.5/1.5 refers to a rather \"good\" or \"poor\" model performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4819169013877043"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "\n",
    "log_loss(y_test, y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discrete metrics:\n",
    "\n",
    "In the discrete metric case we work with \"hard\" labels intead of \"soft\" labels or probabilities. Soft labels can transformed into hard labels for example using threshold for binary classification: e.g. if value > 0.5 then we consider it as a positive class and replace it with 1; otherwise we consider it as a negative class and replace it with 0.\n",
    "\n",
    "In order to introduce all common discrete metrics we need to get familiar with the **confusion matrix** that consists of 4 components:\n",
    "- **TP (True Positive)** - number of pairs for which $y_{i}=1$ and $hard\\_label(\\hat{y_{i}})=1$ i.e. number of positives that were predicted as positives by the model\n",
    "- **TN (True Negative)** - number of pairs for which $y_{i}=0$ and $hard\\_label(\\hat{y_{i}})=0$ i.e. number of negatives that were predicted as negatives by the model\n",
    "- **FP (False Positive)** - number of pairs for which $y_{i}=0$ and $hard\\_label(\\hat{y_{i}})=1$ i.e. number of negatives that were predicted as positives by the model\n",
    "- **FN (False Negative)** - number of pairs for which $y_{i}=1$ and $hard\\_label(\\hat{y_{i}})=0$ i.e. number of positives that were predicted as negatives by the model\n",
    "\n",
    "![](https://assets-global.website-files.com/5d7b77b063a9066d83e1209c/63b413d2cdc133446aa23fc5_636b9182cfaef2115e028921_HERO_1_Confusion.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1156  162]\n",
      " [ 302  664]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print(confusion_matrix(y_test, y_hat >= 0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|                | Predicted Negative | Predicted Positive |\n",
    "|:--------------:|--------------------|--------------------|\n",
    "| **Negative Cases** |      TN: 1156      |      FP: 162      |\n",
    "| **Positive Cases** |      FN: 302      |      TP: 664     |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accuracy** <br>\n",
    "Accuracy simply measures *what percent of your predictions were correct*. It's the ratio between the number of correct predictions and the total number of predictions. The downside is that it is hard to optimize and it cares about hard labels\n",
    "\n",
    "$$accuracy = {\\frac{TP + TN}{TP + FP + FN + TN}}$$\n",
    "\n",
    "##### Pros:\n",
    "    + Highly interpretable by non-technical people\n",
    "    + Limited in range [0, 1]\n",
    "    + Multiclass extension: can be extended to multiclass classification problems, where there are more than two classes\n",
    "\n",
    "##### Cons:\n",
    "    - Not resistant to class imbalance\n",
    "    - Doesn't have \"reference values\": without knowing the task and classes distribution it's hard to tell whether e.g. 0.6/0.8/0.99 refers to a rather \"good\" or \"poor\" model performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7968476357267951"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(y_test, y_hat >= 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Precision & Recall**\n",
    "\n",
    "Precision and recall are actually two metrics. But they are often used together.\n",
    "\n",
    "**Precision** answers the question: *What percent of positive predictions were correct?*\n",
    "\n",
    "$$precision = {\\frac{TP}{TP + FP}}$$\n",
    "\n",
    "**Recall** answers the question: *What percent of the positive cases did you catch?*\n",
    "\n",
    "$$recall = {\\frac{TP}{TP + FN}}$$\n",
    "\n",
    "##### Pros:\n",
    "    + Highly interpretable by non-technical people\n",
    "    + Limited in range [0, 1]\n",
    "    + Multiclass extension: can be extended to multiclass classification problems, where there are more than two classes\n",
    "\n",
    "##### Cons:\n",
    "    - Doesn't take into account TN\n",
    "    - Do not make sense without each other\n",
    "    - Strongly depend on the threshold\n",
    "\n",
    "**F1-score**\n",
    "The F1-score (sometimes known as the balanced F-beta score with beta=1) is a single metric that combines both precision and recall via their harmonic mean:\n",
    "\n",
    "$$F_1 = 2*{\\frac{precision * recall}{precision + recall}}$$\n",
    "\n",
    "Unlike the arithmetic mean, the harmonic mean tends toward the smaller of the two elements. Hence the F1 score will be small if either precision or recall is small.\n",
    "We actually need F1 score because in many cases we can make precision almost as close to 1 as possible but this will result a poor recall and vice-versa.\n",
    "\n",
    "##### Pros:\n",
    "    + Limited in range [0, 1]\n",
    "    + Suitable for imbalanced classes case\n",
    "    + Multiclass extension: can be extended to multiclass classification problems, where there are more than two classes\n",
    "\n",
    "##### Cons:\n",
    "    - Poorly interpretable (especially for people without IT/ML background)\n",
    "    - Doesn't take into account TN\n",
    "    - Strongly depend on the threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>positives_ratio</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.10</th>\n",
       "      <td>0.982925</td>\n",
       "      <td>0.428508</td>\n",
       "      <td>0.995859</td>\n",
       "      <td>0.599190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.25</th>\n",
       "      <td>0.719790</td>\n",
       "      <td>0.543796</td>\n",
       "      <td>0.925466</td>\n",
       "      <td>0.685057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.50</th>\n",
       "      <td>0.361646</td>\n",
       "      <td>0.803874</td>\n",
       "      <td>0.687371</td>\n",
       "      <td>0.741071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.75</th>\n",
       "      <td>0.142732</td>\n",
       "      <td>0.944785</td>\n",
       "      <td>0.318841</td>\n",
       "      <td>0.476780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.90</th>\n",
       "      <td>0.014011</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.033126</td>\n",
       "      <td>0.064128</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      positives_ratio  precision    recall        f1\n",
       "0.10         0.982925   0.428508  0.995859  0.599190\n",
       "0.25         0.719790   0.543796  0.925466  0.685057\n",
       "0.50         0.361646   0.803874  0.687371  0.741071\n",
       "0.75         0.142732   0.944785  0.318841  0.476780\n",
       "0.90         0.014011   1.000000  0.033126  0.064128"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "f_metrics = []\n",
    "tholds = [0.1, 0.25, 0.5, 0.75, 0.9]\n",
    "for th in [0.1, 0.25, 0.5, 0.75, 0.9]:\n",
    "    f_metrics.append({\n",
    "        'positives_ratio': (y_hat >= th).sum()/y_hat.shape[0],\n",
    "        'precision': precision_score(y_test, y_hat >= th),\n",
    "        'recall': recall_score(y_test, y_hat >= th),\n",
    "        'f1': f1_score(y_test, y_hat >= th),\n",
    "    })\n",
    "pd.DataFrame(f_metrics, index=tholds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ROC-AUC**\n",
    "\n",
    "The ROC curve is created by plotting the true positive rate (TPR) against the false positive rate (FPR) at various threshold settings.\n",
    "\n",
    "- **TPR/Recall** - *What percent of the positive cases did you catch?* \n",
    "$$TPR = {\\frac{TP}{TP + FN}}$$\n",
    "- **FPR/Fall-out** - *What percent of negatives would be classified as positives?* \n",
    "$$FPR = {\\frac{FP}{FP + TN}}$$\n",
    "\n",
    "$$ROCAUC = \\int_{t=0}^{1} TPR(t) \\,dFPR(t)$$\n",
    "\n",
    "![](https://machinelearningmastery.com/wp-content/uploads/2018/08/ROC-Curve-Plot-for-a-No-Skill-Classifier-and-a-Logistic-Regression-Model.png)\n",
    "\n",
    "##### Pros:\n",
    "    + Limited in range [0, 1]\n",
    "    + Doesn't depend on the threshold\n",
    "    + Takes all TP/FP/FN/TN into account\n",
    "    + Has some reference values, e.g. 0.5 - random prediction, 0.8-0.9 in balanced case - good, ~1 ideal prediction, \n",
    "    \n",
    "##### Cons:\n",
    "    - Poorly interpretable (especially for people without IT/ML background)\n",
    "    - Doesn't distinguish between different types of errors (false positives and false negatives). In some imbalanced scenarios, you may want to prioritize one type of error over the other.\n",
    "    \n",
    "**PRECISION-RECALL-AUC**\n",
    "\n",
    "The PRECISION-RECALL curve is created by plotting Precision against Recall at various threshold settings.\n",
    "\n",
    "\n",
    "$$PRECISION\\_RECALL\\_AUC = \\int_{t=0}^{1} PRECISION(t) \\,dRECALL(t)$$\n",
    "\n",
    "![](https://machinelearningmastery.com/wp-content/uploads/2020/01/Precision-Recall-Curve-of-a-Logistic-Regression-Model-and-a-No-Skill-Classifier2.png)\n",
    "\n",
    "##### Pros:\n",
    "    + Limited in range [0, 1]\n",
    "    + Doesn't depend on the threshold\n",
    "    + Very useful for tasks with a huge class imbalance\n",
    "    \n",
    "##### Cons:\n",
    "    - Poorly interpretable (especially for people without IT/ML background)\n",
    "    - Doesn't take into account TN\n",
    "    - Doesn't have reference values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC = 0.8530923948387826\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PR-AUC = 0.8406347298926266\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, roc_curve, auc\n",
    "\n",
    "# plot no skill and model roc curves\n",
    "def plot_roc_curve(test_y, model_probs):\n",
    "    fpr, tpr, _ = roc_curve(test_y, model_probs)\n",
    "    pyplot.plot(fpr, tpr, marker='.', label='Logistic')\n",
    "    pyplot.xlabel('False Positive Rate')\n",
    "    pyplot.ylabel('True Positive Rate')\n",
    "    pyplot.legend()\n",
    "    pyplot.show()\n",
    "    \n",
    "# plot model precision-recall curves\n",
    "def plot_pr_curve(test_y, model_probs):\n",
    "    precision, recall, _ = precision_recall_curve(test_y, model_probs)\n",
    "    pyplot.plot(recall, precision, marker='.', label='Logistic')\n",
    "    pyplot.xlabel('Recall')\n",
    "    pyplot.ylabel('Precision')\n",
    "    pyplot.legend()\n",
    "    pyplot.show()\n",
    "\n",
    "\n",
    "print(f'ROC-AUC = {roc_auc_score(y_test, y_hat)}')\n",
    "plot_roc_curve(y_test, y_hat)\n",
    "\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_hat)\n",
    "pr_auc_score = auc(recall, precision)\n",
    "print(f'PR-AUC = {pr_auc_score}')\n",
    "plot_pr_curve(y_test, y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imbalanced classes case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_class_index = y_test[y_test == 0].index\n",
    "positive_class_index = y_test[y_test == 1].sample(frac=0.05).index\n",
    "imbalanced_sumsample_index = negative_class_index.append(positive_class_index)\n",
    "\n",
    "y_test_imbalanced = y_test.loc[imbalanced_sumsample_index]\n",
    "y_hat_imbalanced = pipe_classification.predict_proba(X_test.loc[imbalanced_sumsample_index])[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC = 0.8452990642387455\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PR-AUC = 0.3100912881643857\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(f'ROC-AUC = {roc_auc_score(y_test_imbalanced, y_hat_imbalanced)}')\n",
    "plot_roc_curve(y_test_imbalanced, y_hat_imbalanced)\n",
    "\n",
    "precision, recall, _ = precision_recall_curve(y_test_imbalanced, y_hat_imbalanced)\n",
    "pr_auc_score = auc(recall, precision)\n",
    "print(f'PR-AUC = {pr_auc_score}')\n",
    "plot_pr_curve(y_test_imbalanced, y_hat_imbalanced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='regression_metrics'></a>\n",
    "## 2.3 Regression metrics\n",
    "\n",
    "A regression task, in machine learning, is a type of supervised learning problem where the goal is to predict a continuous numeric value or a real number. In regression tasks, the target variable is continuous, and the model's objective is to learn a mapping from input features to this continuous output.\n",
    "\n",
    "Let's take a look at some common metrics using NLP example [CommonLit - Evaluate Student Summaries](https://www.kaggle.com/competitions/commonlit-evaluate-student-summaries/overview):<br>\n",
    "The goal of this competition is to assess the quality of summaries written by students in grades 3-12. You'll build a model that evaluates how well a student represents the main idea and details of a source text, as well as the clarity, precision, and fluency of the language used in the summary. You'll have access to a collection of real student summaries to train your model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading commonlit-evaluate-student-summaries.zip to /Users/abazdyrev/JupyterNotebooks/iasa_nlp_course/Lecture_3\n",
      " 95%|████████████████████████████████████▏ | 1.00M/1.05M [00:00<00:00, 1.54MB/s]\n",
      "100%|██████████████████████████████████████| 1.05M/1.05M [00:00<00:00, 1.60MB/s]\n",
      "Archive:  commonlit-evaluate-student-summaries.zip\n",
      "  inflating: commonlit-evaluate-student-summaries/prompts_test.csv  \n",
      "  inflating: commonlit-evaluate-student-summaries/prompts_train.csv  \n",
      "  inflating: commonlit-evaluate-student-summaries/sample_submission.csv  \n",
      "  inflating: commonlit-evaluate-student-summaries/summaries_test.csv  \n",
      "  inflating: commonlit-evaluate-student-summaries/summaries_train.csv  \n"
     ]
    }
   ],
   "source": [
    "!kaggle competitions download -c commonlit-evaluate-student-summaries\n",
    "!unzip commonlit-evaluate-student-summaries.zip -d commonlit-evaluate-student-summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>prompt_question</th>\n",
       "      <th>prompt_title</th>\n",
       "      <th>prompt_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39c16e</td>\n",
       "      <td>Summarize at least 3 elements of an ideal trag...</td>\n",
       "      <td>On Tragedy</td>\n",
       "      <td>Chapter 13 \\r\\nAs the sequel to what has alrea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3b9047</td>\n",
       "      <td>In complete sentences, summarize the structure...</td>\n",
       "      <td>Egyptian Social Structure</td>\n",
       "      <td>Egyptian society was structured like a pyramid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>814d6b</td>\n",
       "      <td>Summarize how the Third Wave developed over su...</td>\n",
       "      <td>The Third Wave</td>\n",
       "      <td>Background \\r\\nThe Third Wave experiment took ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ebad26</td>\n",
       "      <td>Summarize the various ways the factory would u...</td>\n",
       "      <td>Excerpt from The Jungle</td>\n",
       "      <td>With one member trimming beef in a cannery, an...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  prompt_id                                    prompt_question  \\\n",
       "0    39c16e  Summarize at least 3 elements of an ideal trag...   \n",
       "1    3b9047  In complete sentences, summarize the structure...   \n",
       "2    814d6b  Summarize how the Third Wave developed over su...   \n",
       "3    ebad26  Summarize the various ways the factory would u...   \n",
       "\n",
       "                prompt_title  \\\n",
       "0                 On Tragedy   \n",
       "1  Egyptian Social Structure   \n",
       "2             The Third Wave   \n",
       "3    Excerpt from The Jungle   \n",
       "\n",
       "                                         prompt_text  \n",
       "0  Chapter 13 \\r\\nAs the sequel to what has alrea...  \n",
       "1  Egyptian society was structured like a pyramid...  \n",
       "2  Background \\r\\nThe Third Wave experiment took ...  \n",
       "3  With one member trimming beef in a cannery, an...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_promts = pd.read_csv('commonlit-evaluate-student-summaries/prompts_train.csv')\n",
    "df_summaries = pd.read_csv('commonlit-evaluate-student-summaries/summaries_train.csv')\n",
    "df_promts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>student_id</th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>text</th>\n",
       "      <th>content</th>\n",
       "      <th>wording</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1812</th>\n",
       "      <td>41764ac8949a</td>\n",
       "      <td>ebad26</td>\n",
       "      <td>From the text, For it was the custom, as they ...</td>\n",
       "      <td>-1.547163</td>\n",
       "      <td>-1.461245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5738</th>\n",
       "      <td>cc41fecee9f7</td>\n",
       "      <td>814d6b</td>\n",
       "      <td>The Third Wave developed in such a short perio...</td>\n",
       "      <td>-0.185162</td>\n",
       "      <td>1.053104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>06e2ecfb993d</td>\n",
       "      <td>3b9047</td>\n",
       "      <td>At the top of the pyramids would be what they ...</td>\n",
       "      <td>0.985008</td>\n",
       "      <td>0.623245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1014</th>\n",
       "      <td>248054546a1a</td>\n",
       "      <td>ebad26</td>\n",
       "      <td>They would cover up spoiled meat by preserving...</td>\n",
       "      <td>-1.264214</td>\n",
       "      <td>-1.505073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5538</th>\n",
       "      <td>c4e6a9b0c6db</td>\n",
       "      <td>814d6b</td>\n",
       "      <td>The third wave started as an experiment on con...</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>1.424724</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        student_id prompt_id  \\\n",
       "1812  41764ac8949a    ebad26   \n",
       "5738  cc41fecee9f7    814d6b   \n",
       "187   06e2ecfb993d    3b9047   \n",
       "1014  248054546a1a    ebad26   \n",
       "5538  c4e6a9b0c6db    814d6b   \n",
       "\n",
       "                                                   text   content   wording  \n",
       "1812  From the text, For it was the custom, as they ... -1.547163 -1.461245  \n",
       "5738  The Third Wave developed in such a short perio... -0.185162  1.053104  \n",
       "187   At the top of the pyramids would be what they ...  0.985008  0.623245  \n",
       "1014  They would cover up spoiled meat by preserving... -1.264214 -1.505073  \n",
       "5538  The third wave started as an experiment on con...  0.782609  1.424724  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_summaries.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://www.googleapis.com/download/storage/v1/b/kaggle-forum-message-attachments/o/inbox%2F9174368%2F195e02a7cf40fbf40e1179bad1cdd017%2Fcontent_wording_graphic.png?generation=1689711455437198&alt=media)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAV7ElEQVR4nO3dbYxU53nG8f9VnGASYoPlDaUsKrQh2wCbpMGlpFarIXYLjS1Dq1paC8e4cbWqRVKnWiuB+oPVD6uipqSN5eJqZZCx7JpuiVNQLJJQmpEVyZiA42QNmHgbqLPGgaZ+iddxiZfc/TDH0nQ9eHfOvO3Oc/0ktDP3ebsfWK45c+bMOYoIzMwsDb/U6gbMzKx5HPpmZglx6JuZJcShb2aWEIe+mVlCLml1AxOZM2dOfOADH2h1G3X3+uuv8973vrfVbdSdxzX9tOvYUh/X0aNHfxIRHePrUz70582bx5EjR1rdRt0Vi0UKhUKr26g7j2v6adexpT4uSf9Vqe7DO2ZmCXHom5klxKFvZpYQh76ZWUIc+mZmCXHom5klxKFvZpYQh76ZWUIc+mZmCZny38i16iza/FhLtnt663Ut2a6ZVcd7+mZmCXHom5klxKFvZpYQh76ZWUIc+mZmCZkw9CXtlHRO0jPj6p+VdFLSMUl/W1bfImk4m7amrL5C0lA27R5Jqu9QzMxsIpPZ038AWFtekLQaWAd8OCKWAX+X1ZcCPcCybJntkmZki90H9AJLsj//b51mZtZ4E4Z+RDwOvDSufDuwNSLOZ/Ocy+rrgN0RcT4iTgHDwEpJ84HLIuKJiAjgQWB9ncZgZmaTlPfLWR8EfldSP/C/wJ0R8R1gAXCobL6RrPZm9nh8vSJJvZTeFdDR0UGxWMzZ5tQ1OjrakHH1dY/VfZ2T8dZYGjWuVmvXcUH7js3jqixv6F8CzAVWAb8FDEr6NaDScfp4h3pFETEADAB0dXVFyve5rNatrfpG7oYC4PuSTkftOjaPq7K8Z++MAI9GyWHgF8CVWX1h2XydwJms3lmhbmZmTZQ39P8N+ASApA8C7wZ+AuwDeiTNlLSY0ge2hyPiReA1Sauys3ZuAfbW2ryZmVVnwsM7kh4BCsCVkkaAu4GdwM7sNM6fAxuzD2iPSRoEjgNjwKaIuJCt6nZKZwLNAvZnf8zMrIkmDP2IuOkik26+yPz9QH+F+hFgeVXdmZlZXfkbuWZmCXHom5klxKFvZpYQh76ZWUJ8u0Sri7du09jXPdb0L4j5Vo1mk+c9fTOzhDj0zcwS4tA3M0uIQ9/MLCEOfTOzhDj0zcwS4tA3M0uIQ9/MLCEOfTOzhDj0zcwS4tA3M0vIhKEvaaekc9ldssZPu1NSSLqyrLZF0rCkk5LWlNVXSBrKpt2T3TbRzMyaaDJ7+g8Aa8cXJS0Efh94vqy2FOgBlmXLbJc0I5t8H9BL6b65Syqt08zMGmvC0I+Ix4GXKkz6e+DzQJTV1gG7I+J8RJwChoGVkuYDl0XEE9m9dB8E1tfavJmZVSfXpZUl3QC8EBHfG3eUZgFwqOz5SFZ7M3s8vn6x9fdSeldAR0cHxWIxT5tT2ujoaEPG1dc9Vvd1VmPerOb30Izfj0b9e00F7To2j6uyqkNf0nuAu4A/qDS5Qi3eoV5RRAwAAwBdXV1RKBSqbXPKKxaLNGJczb6W/Xh93WNsG2rubRpObyg0fBuN+veaCtp1bB5XZXn+d/46sBh4ay+/E3hK0kpKe/ALy+btBM5k9c4KdTMza6KqT9mMiKGIeH9ELIqIRZQC/WMR8WNgH9AjaaakxZQ+sD0cES8Cr0lalZ21cwuwt37DMDOzyZjMKZuPAE8AXZJGJN12sXkj4hgwCBwHvg5siogL2eTbgfspfbj7n8D+Gns3M7MqTXh4JyJummD6onHP+4H+CvMdAZZX2Z+ZmdWRv5FrZpYQh76ZWUIc+mZmCXHom5klxKFvZpYQh76ZWUIc+mZmCXHom5klxKFvZpYQh76ZWUIc+mZmCXHom5klxKFvZpYQh76ZWUIc+mZmCXHom5klZDJ3ztop6ZykZ8pqX5T0rKTvS/qqpDll07ZIGpZ0UtKasvoKSUPZtHuy2yaamVkTTWZP/wFg7bjaAWB5RHwY+AGwBUDSUqAHWJYts13SjGyZ+4BeSvfNXVJhnWZm1mAThn5EPA68NK72zYgYy54eAjqzx+uA3RFxPiJOUbof7kpJ84HLIuKJiAjgQWB9ncZgZmaTNOE9cifh08C/ZI8XUHoReMtIVnszezy+XpGkXkrvCujo6KBYLNahzalldHS0IePq6x6beKYGmjer+T004/ejUf9eU0G7js3jqqym0Jd0FzAGPPxWqcJs8Q71iiJiABgA6OrqikKhUEubTbdo82MTztPXfYFt3369AVuvx+t4fn3dY2wbam4PpzcUGr6NYrHIdPs9nKx2HZvHVVnu/52SNgLXA9dkh2ygtAe/sGy2TuBMVu+sUDczsybKdcqmpLXAF4AbIuJnZZP2AT2SZkpaTOkD28MR8SLwmqRV2Vk7twB7a+zdzMyqNOGevqRHgAJwpaQR4G5KZ+vMBA5kZ14eiog/j4hjkgaB45QO+2yKiAvZqm6ndCbQLGB/9sfMzJpowtCPiJsqlHe8w/z9QH+F+hFgeVXdmZlZXfkbuWZmCXHom5klxKFvZpYQh76ZWUIc+mZmCXHom5klxKFvZpYQh76ZWUIc+mZmCXHom5klxKFvZpYQh76ZWUIc+mZmCXHom5klxKFvZpaQCUNf0k5J5yQ9U1a7QtIBSc9lP+eWTdsiaVjSSUlryuorJA1l0+7J7qBlZmZNNJk9/QeAteNqm4GDEbEEOJg9R9JSoAdYli2zXdKMbJn7gF5Kt1BcUmGdZmbWYJO5c9bjkhaNK6+jdAtFgF1AkdI9c9cBuyPiPHBK0jCwUtJp4LKIeAJA0oPAehp8y8RFmx9r5OrNzKadCUP/IuZlNzsnIl6U9P6svgA4VDbfSFZ7M3s8vl6RpF5K7wro6OigWCzmarKveyzXcs0wb9bU7i+vVowr7+9HNUZHR5uynVZo17F5XJXlDf2LqXScPt6hXlFEDAADAF1dXVEoFHI1c+sU3tPv6x5j21C9//pbrxXjOr2h0PBtFItF8v4eTnXtOjaPq7K8Z++clTQfIPt5LquPAAvL5usEzmT1zgp1MzNroryhvw/YmD3eCOwtq/dImilpMaUPbA9nh4Jek7QqO2vnlrJlzMysSSZ8Hy7pEUof2l4paQS4G9gKDEq6DXgeuBEgIo5JGgSOA2PApoi4kK3qdkpnAs2i9AFuQz/ENTOzt5vM2Ts3XWTSNReZvx/or1A/AiyvqjszM6srfyPXzCwhDn0zs4Q49M3MEuLQNzNLiEPfzCwhDn0zs4Q49M3MEuLQNzNLiEPfzCwhDn0zs4Q49M3MEuLQNzNLiEPfzCwhDn0zs4Q49M3MEuLQNzNLSE2hL+kvJR2T9IykRyRdKukKSQckPZf9nFs2/xZJw5JOSlpTe/tmZlaN3KEvaQHwF8BVEbEcmAH0AJuBgxGxBDiYPUfS0mz6MmAtsF3SjNraNzOzatR6eOcSYJakS4D3AGeAdcCubPouYH32eB2wOyLOR8QpYBhYWeP2zcysCoqI/AtLd1C6H+4bwDcjYoOkVyJiTtk8L0fEXEn3Aoci4qGsvgPYHxF7Kqy3F+gF6OjoWDE4OJirv6EXXs21XDPMmwVn32h1F/XXinF1L7i84dsYHR1l9uzZDd9OK7Tr2FIf1+rVq49GxFXj6xPeGP1ismP164DFwCvAv0q6+Z0WqVCr+IoTEQPAAEBXV1cUCoVcPd66+bFcyzVDX/cY24Zy//VPWa0Y1+kNhYZvo1gskvf3cKpr17F5XJXVcnjnWuBURPx3RLwJPAr8DnBW0nyA7Oe5bP4RYGHZ8p2UDgeZmVmT1BL6zwOrJL1HkoBrgBPAPmBjNs9GYG/2eB/QI2mmpMXAEuBwDds3M7Mq5X4fHhFPStoDPAWMAd+ldEhmNjAo6TZKLww3ZvMfkzQIHM/m3xQRF2rs38zMqlDTwdeIuBu4e1z5PKW9/krz91P64NfMzFrA38g1M0uIQ9/MLCEOfTOzhDj0zcwS4tA3M0uIQ9/MLCEOfTOzhDj0zcwS0n5X/LLkLGrChfX6usfedgG/01uva/h2zerNe/pmZglx6JuZJcShb2aWEIe+mVlCHPpmZglx6JuZJcShb2aWkJpCX9IcSXskPSvphKSPS7pC0gFJz2U/55bNv0XSsKSTktbU3r6ZmVWj1j39LwNfj4jfAD5C6R65m4GDEbEEOJg9R9JSoAdYBqwFtkuaUeP2zcysCrlDX9JlwO8BOwAi4ucR8QqwDtiVzbYLWJ89XgfsjojzEXEKGAZW5t2+mZlVTxGRb0Hpo5RuhH6c0l7+UeAO4IWImFM238sRMVfSvcChiHgoq+8A9kfEngrr7gV6ATo6OlYMDg7m6nHohVdzLdcM82bB2Tda3UX9pTSu7gWXt6aZOhsdHWX27NmtbqPuUh/X6tWrj0bEVePrtVx75xLgY8BnI+JJSV8mO5RzEapQq/iKExEDlF5Q6OrqikKhkKvB8ddKmUr6usfYNtR+lz5KaVynNxRa00ydFYtF8v4fm8o8rspqOaY/AoxExJPZ8z2UXgTOSpoPkP08Vzb/wrLlO4EzNWzfzMyqlDv0I+LHwI8kdWWlaygd6tkHbMxqG4G92eN9QI+kmZIWA0uAw3m3b2Zm1av1ffhngYclvRv4IfCnlF5IBiXdBjwP3AgQEcckDVJ6YRgDNkXEhRq3b2ZmVagp9CPiaeBtHxRQ2uuvNH8/0F/LNs3MLD9/I9fMLCEOfTOzhDj0zcwS4tA3M0uIQ9/MLCEOfTOzhDj0zcwS4tA3M0uIQ9/MLCEOfTOzhDj0zcwS0n4XPjdrkkUtvF/D6a3XtWzbNr15T9/MLCEOfTOzhDj0zcwSUnPoS5oh6buSvpY9v0LSAUnPZT/nls27RdKwpJOS1tS6bTMzq0499vTvAE6UPd8MHIyIJcDB7DmSlgI9wDJgLbBd0ow6bN/MzCapptCX1AlcB9xfVl4H7Moe7wLWl9V3R8T5iDgFDAMra9m+mZlVRxGRf2FpD/A3wPuAOyPiekmvRMScsnlejoi5ku4FDkXEQ1l9B7A/IvZUWG8v0AvQ0dGxYnBwMFd/Qy+8mmu5Zpg3C86+0eou6s/jao7uBZfXbV2jo6PMnj27buubKlIf1+rVq49GxNtuZ5v7PH1J1wPnIuKopMJkFqlQq/iKExEDwABAV1dXFAqTWf3b3drC86gn0tc9xrah9vuahMfVHKc3FOq2rmKxSN7/Y1OZx1VZLb/FVwM3SPokcClwmaSHgLOS5kfEi5LmA+ey+UeAhWXLdwJnati+mZlVKXfoR8QWYAtAtqd/Z0TcLOmLwEZga/Zzb7bIPuCfJX0J+BVgCXA4d+dmCavnt4H7uscm/a7Y3wSe/hrxfnUrMCjpNuB54EaAiDgmaRA4DowBmyLiQgO2b2ZmF1GX0I+IIlDMHv8PcM1F5usH+uuxTTMzq56/kWtmlhCHvplZQhz6ZmYJceibmSXEoW9mlhCHvplZQhz6ZmYJceibmSXEoW9mlhCHvplZQhz6ZmYJceibmSXEoW9mlhCHvplZQhz6ZmYJceibmSUkd+hLWijpW5JOSDom6Y6sfoWkA5Key37OLVtmi6RhSSclranHAMzMbPJq2dMfA/oi4kPAKmCTpKXAZuBgRCwBDmbPyab1AMuAtcB2STNqad7MzKqTO/Qj4sWIeCp7/BpwAlgArAN2ZbPtAtZnj9cBuyPifEScAoaBlXm3b2Zm1VNE1L4SaRHwOLAceD4i5pRNezki5kq6FzgUEQ9l9R3A/ojYU2F9vUAvQEdHx4rBwcFcfQ298Gqu5Zph3iw4+0aru6g/j2v6qWZs3Qsub2wzdTQ6Osrs2bNb3UbdTXZcq1evPhoRV42v13xjdEmzga8An4uIn0q66KwVahVfcSJiABgA6OrqikKhkKu3Wzc/lmu5ZujrHmPbUF3uSz+leFzTTzVjO72h0Nhm6qhYLJI3O6ayWsdV09k7kt5FKfAfjohHs/JZSfOz6fOBc1l9BFhYtngncKaW7ZuZWXVqOXtHwA7gRER8qWzSPmBj9ngjsLes3iNppqTFwBLgcN7tm5lZ9Wp5v3o18ClgSNLTWe2vgK3AoKTbgOeBGwEi4pikQeA4pTN/NkXEhRq2b2ZmVcod+hHxbSofpwe45iLL9AP9ebdpZma18TdyzcwS4tA3M0uIQ9/MLCHteeKxmTXEohZ99+X01utast125D19M7OEOPTNzBLi0DczS4hD38wsIQ59M7OE+OwdM5vy8pw11Nc9Vpcr7bbbmUPe0zczS4hD38wsIQ59M7OEOPTNzBLi0DczS4hD38wsIU0/ZVPSWuDLwAzg/ojY2uwezMwmq90uMtfUPX1JM4B/BP4QWArcJGlpM3swM0tZsw/vrASGI+KHEfFzYDewrsk9mJklSxHRvI1JfwKsjYg/y55/CvjtiPjMuPl6gd7s6XLgmaY12TxXAj9pdRMN4HFNP+06ttTH9asR0TG+2Oxj+pVupP62V52IGAAGACQdiYirGt1Ys3lc00u7jgvad2weV2XNPrwzAiwse94JnGlyD2ZmyWp26H8HWCJpsaR3Az3Avib3YGaWrKYe3omIMUmfAb5B6ZTNnRFxbILFBhrfWUt4XNNLu44L2ndsHlcFTf0g18zMWsvfyDUzS4hD38wsIdMi9CV9UdKzkr4v6auS5rS6p3qQdKOkY5J+IWnan1omaa2kk5KGJW1udT/1IGmnpHOS2uq7IpIWSvqWpBPZ7+Adre6pHiRdKumwpO9l4/rrVvdUT5JmSPqupK/lXce0CH3gALA8Ij4M/ADY0uJ+6uUZ4I+Bx1vdSK3a+BIbDwBrW91EA4wBfRHxIWAVsKlN/r3OA5+IiI8AHwXWSlrV2pbq6g7gRC0rmBahHxHfjIix7OkhSuf3T3sRcSIiTra6jzppy0tsRMTjwEut7qPeIuLFiHgqe/wapSBZ0Nquahclo9nTd2V/2uJsFUmdwHXA/bWsZ1qE/jifBva3ugl7mwXAj8qej9AGIZICSYuA3wSebHErdZEdAnkaOAcciIi2GBfwD8DngV/UspKmX1r5YiT9O/DLFSbdFRF7s3nuovS29OFm9laLyYyrTUzqEhs2tUiaDXwF+FxE/LTV/dRDRFwAPpp99vdVScsjYlp/JiPpeuBcRByVVKhlXVMm9CPi2neaLmkjcD1wTUyjLxdMNK424ktsTDOS3kUp8B+OiEdb3U+9RcQrkoqUPpOZ1qEPXA3cIOmTwKXAZZIeioibq13RtDi8k9145QvADRHxs1b3YxX5EhvTiCQBO4ATEfGlVvdTL5I63jq7T9Is4Frg2ZY2VQcRsSUiOiNiEaX/W/+RJ/BhmoQ+cC/wPuCApKcl/VOrG6oHSX8kaQT4OPCYpG+0uqe8sg/a37rExglgcBKX2JjyJD0CPAF0SRqRdFure6qTq4FPAZ/I/k89ne1FTnfzgW9J+j6lHZEDEZH79MZ25MswmJklZLrs6ZuZWR049M3MEuLQNzNLiEPfzCwhDn0zs4Q49M3MEuLQNzNLyP8BlkXz9wspFI0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_summaries.content.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_summaries.wording.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#straightforward train/test split - this approach is actually SO WRONG here!!\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df_summaries.text, df_summaries.wording, test_size=0.3, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "#modeling and inference\n",
    "\n",
    "pipe_regression = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer(\n",
    "        analyzer='word',\n",
    "        stop_words='english',\n",
    "        ngram_range=(1, 3),\n",
    "        lowercase=True,\n",
    "        min_df=5,\n",
    "        max_features=30000\n",
    "    )),  \n",
    "    ('classifier', Ridge(alpha=1.0, random_state=42))\n",
    "])\n",
    "\n",
    "pipe_regression.fit(X_train, y_train)\n",
    "\n",
    "y_hat = pipe_regression.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MSE (L2 Loss) and RMSE:** <br>\n",
    "MSE measures your mean square error from target:\n",
    "\n",
    "\n",
    "$$ MSE = {\\frac{1}{N} \\sum_{i=1}^{N}(y_{i}-\\hat{y_{i}})^2}$$\n",
    "\n",
    "$$ RMSE = {\\sqrt{MSE}}$$\n",
    "\n",
    "RMSE and MSE is similiar in terms of minimizers - value minimizes RMSE **if and only if** it minimizes MSE. This means that in terms of competitions we can optimize MSE instead of RMSE. In fact it is easier to work with MSE. But there is a little bit of difference between the two for gradient-based models. The gradient of RMSE with respect to i-th prediction is basically equal to gradient of MSE multiplied by some value. The value doesn't depend on the index I. It means that travelling along MSE gradient is equivalent to traveling along RMSE gradient but with a different flowing rate and the flowing rate depends on MSE score itself. So, it is kind of dynamic.So even though RMSE and MSE are really similar in terms of models scoring, they can be not immediately interchangeable for gradient based methods. We will probably need to adjust some parameters like the learning rate.\n",
    "\n",
    "##### Pros:\n",
    "    + Differentiable\n",
    "    + Could be a loss\n",
    "    + According to the Gauss-Markov theorem optimizing MSE results in BLUE (The best linear unbiased estimator) for linear models if the conditions of the theorem are fulfilled\n",
    "\n",
    "##### Cons:\n",
    "    - Sensitive for outliers: Optimizing MSE could produce a non-robust estimator\n",
    "    - Doesn't have reference values: without knowing the scale of the target variable it's hard to tell whether e.g. 0.5/5/50 values are good or not\n",
    "\n",
    "**R-squared** <br>\n",
    "To see model performance in terms of dummy baseline usually R-squared is used. Or Adjusted R-squared to penalize for model parameters/features\n",
    "\n",
    "$$ R^2 = 1 - {\\frac{MSE}{\\frac{1}{N} \\sum_{i=1}^{N}(y_{i}-\\bar{y_{i}})^2}}$$\n",
    "\n",
    "In a normal scenario R-squared should be between 0 and 1.\n",
    "\n",
    "##### Pros:\n",
    "    + Differentiable\n",
    "    + Could be a loss\n",
    "    + Has reference values: < 0 -> model performs worse than the \"blind guess\"; greater than 0 -> model performs better than the \"blind guess\"; ~1 - we have a perfect model\n",
    "\n",
    "##### Cons:\n",
    "    - Sensitive for outliers\n",
    "    \n",
    "#### Outliers case:\n",
    "![](https://machinelearningmastery.com/wp-content/uploads/2020/03/Comparison-of-Robust-Regression-Algorithms-Line-of-Best-Fit.png)\n",
    "\n",
    "**MAE (L1 Loss / Manhattan Distance):**\n",
    "\n",
    "$$ MAE = {\\frac{1}{N} \\sum_{i=1}^{N}|y_{i}-\\hat{y_{i}}|} $$\n",
    "\n",
    "##### Pros:\n",
    "    + Differentiable \"almost everywhere\". Although, it is not differentiable in 0, but you can simply overcome that by coding simple *if else* condition.\n",
    "    + Could be a loss\n",
    "    + Less sensitive to outliers, so produces more robust estimators\n",
    "\n",
    "##### Cons:\n",
    "    - Doesn't have reference values: without knowing the scale of the target variable it's hard to tell whether e.g. 0.5/5/50 values are good or not\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>0.474720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mean_absolute_error</td>\n",
       "      <td>0.544471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>r2_score</td>\n",
       "      <td>0.552307</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                metric     value\n",
       "0   mean_squared_error  0.474720\n",
       "1  mean_absolute_error  0.544471\n",
       "2             r2_score  0.552307"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "r_metrics = []\n",
    "for metric_fn in [mean_squared_error, mean_absolute_error, r2_score]:\n",
    "    r_metrics.append({'metric': metric_fn.__name__, 'value': metric_fn(y_test, y_hat)})\n",
    "pd.DataFrame(r_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pearson Correlation** <br>\n",
    "\n",
    "The Pearson correlation coefficient, often denoted as \"r,\" is not typically used as a regression loss function in the traditional sense. Instead, it is a measure of the linear relationship or linear association between two continuous variables. It quantifies the strength and direction of the linear relationship between the ground truth target variable and predicted one. The Pearson correlation coefficient ranges from -1 to 1, with the following interpretations: <br>\n",
    "$$ Cov(Y,\\hat{Y}) ={\\frac{1}{N-1}} \\sum_{i=1}^{N}(y_{i} - \\bar{y_{i}})*(\\hat{y_{i}} - \\bar{\\hat{y_{i}}})$$\n",
    "\n",
    "$$PearsonR = {\\frac{Cov(Y,\\hat{Y})}{STD(Y)*STD(\\hat{Y})}}$$\n",
    "\n",
    "##### Pros:\n",
    "    + Differentiable\n",
    "    + Could be a loss. Although, you need to update standard deviation of y_hat\n",
    "    + Has reference values: [-1, 0] - negative linear correlation; [0, ~0.5] weak* linear correlation; [0.5-0.9] strong* linear correlation; [0.9-1] - almost perfect model;\n",
    "\n",
    "##### Cons:\n",
    "    - We can't say anything about absolute errors knowing only correlation coefficient\n",
    "    - Could produce a low values, although it could be a solid monotonous correlation between y and y_hat\n",
    "\n",
    "**Spearman Correlation** <br>\n",
    "\n",
    "The Spearman Correlation coefficient, is calculated as a Pearson correlation coefficient between ranks of target and predicted variables: <br>\n",
    "\n",
    "$$SpearmanR = PearsonR(rank(Y), rank(\\hat{Y}))$$\n",
    "\n",
    "##### Pros:\n",
    "    + Sensitive for monotonous dependencies\n",
    "    + Has reference values: [-1, 0] - negative monotonous correlation; [0, ~0.5] weak* monotonous correlation; [0.5-0.9] strong* monotonous correlation; [0.9-1] - almost perfect model;\n",
    "\n",
    "##### Cons:\n",
    "    - Non-differentiable\n",
    "    - We can't say anything about absolute errors knowing only correlation coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Pearson Correlation: 0.7455920992971997;\n",
      "\n",
      "    Spearman Correlation: 0.7181264430217358\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "print(f\"\"\"\n",
    "    Pearson Correlation: {np.corrcoef(y_test, y_hat)[0, 1]};\\n\n",
    "    Spearman Correlation: {spearmanr(y_test, y_hat).correlation}\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='embedding_metrics'></a>\n",
    "## 2.4 Embedding metrics\n",
    "\n",
    "### Embeddings concept:\n",
    "![](https://miro.medium.com/v2/resize:fit:1200/1*sAJdxEsDjsPMioHyzlN3_A.png)\n",
    "\n",
    "**Cosine similarity:** <br>\n",
    "\n",
    "Cosine similarity is a metric used to measure the similarity or cosine of the angle between two non-zero vectors in a multi-dimensional space. It quantifies how similar two vectors are in terms of their directions, regardless of their magnitudes. Cosine similarity is often employed in various fields, including information retrieval, NLP, recommendation systems, to compare and assess the similarity between data points. <br>\n",
    "\n",
    "Cosine similarity produces a value in the range of -1 to 1:\n",
    "- If the vectors are identical (i.e., they have the same direction), the cosine similarity is 1.\n",
    "- If the vectors are orthogonal (i.e., they are at a right angle to each other), the cosine similarity is 0, indicating no similarity.\n",
    "- If the vectors are pointing in exactly opposite directions, the cosine similarity is -1, indicating maximum dissimilarity.\n",
    "\n",
    "Key properties of cosine similarity:\n",
    "- Scale-Invariant: meaning that multiplying all elements in both vectors by a constant factor will not change the cosine similarity.\n",
    "- Angle Measurement: cosine similarity measures the cosine of the angle between vectors. As the angle decreases (i.e., vectors become more aligned), the cosine similarity value increases.\n",
    "- Normalized Data: cosine similarity is often used with normalized vectors (i.e., vectors with a magnitude of 1) for consistent comparisons.\n",
    "\n",
    "**L1(Manhattan)/L2(Eucledean):** <br>\n",
    "These metrics also could be used as embedding metrics, but they are completely opposite to a cosine similarity in terms of properties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='generative_metrics'></a>\n",
    "## 2.5 Generative NLP metrics\n",
    "\n",
    "Text generation is a challenging field. Both academia and the industry continue to struggle for relevant metrics for evaluation of the generative models’ qualities. Each generative task is unique, characterized by its distinct intricacies and idiosyncrasies. \n",
    "\n",
    "To check evaluations in NLG, Machine-generated texts are usually evaluated against a target text (ground truth value). This target text is what is expected of the model to ideally generate. Generated text refers to the machine produced texts (output of the model), and target or reference text refers to the original truth value text. \n",
    "\n",
    "**BLEU: Bilingual Evaluation Understudy Score**<br>\n",
    "BLEU is a precision focused metric that calculates n-gram overlap of the reference and generated texts. This n-gram overlap means the evaluation scheme is word-position independent apart from n-grams’ term associations. One thing to note in BLEU — there is a brevity penalty i.e. a penalty applied when the generated text is too small compared to the target text.\n",
    "\n",
    "BLEU's output is always a number between 0 and 1. This value indicates how similar the candidate text is to the reference texts, with values closer to 1 representing more similar texts. Few human translations will attain a score of 1, since this would indicate that the candidate is identical to one of the reference translations. For this reason, it is not necessary to attain a score of 1. Because there are more opportunities to match, adding additional reference translations will increase the BLEU score. \n",
    "\n",
    "You can check in detail the exact algorithm and equations for implementation [here](https://en.wikipedia.org/wiki/BLEU)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reference: ['the quick brown fox jumps over the lazy dog']\n",
      "candidate: the fast brown fox jumps over the lazy dog\n",
      "BLEU Score: 0.7506238537503395\n",
      "\n",
      "\n",
      "\n",
      "references: ['the quick brown fox jumps over the lazy dog', 'the fast brown fox jumps over the lazy dog']\n",
      "candidate: the fast brown fox jumps over the lazy dog\n",
      "BLEU Score: 1.0\n",
      "\n",
      "\n",
      "\n",
      "references: ['the quick brown fox jumps over the lazy dog']\n",
      "candidate: the quick brown fox jumps over the dog\n",
      "BLEU Score: 0.767279645960659\n",
      "\n",
      "\n",
      "\n",
      "references: ['the quick brown fox jumps over the lazy dog']\n",
      "candidate: fox jumps over the dog\n",
      "BLEU Score: 0.31772355751081427\n",
      "\n",
      "\n",
      "\n",
      "references: ['the quick brown fox jumps over the lazy dog']\n",
      "candidate: absolutely random sentence\n",
      "BLEU Score: 0\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "# Reference and candidate sentences as lists of words\n",
    "reference = ['the quick brown fox jumps over the lazy dog']\n",
    "candidate = 'the fast brown fox jumps over the lazy dog'\n",
    "\n",
    "# Calculate BLEU score\n",
    "bleu_score = sentence_bleu([r.split() for r in reference], candidate.split())\n",
    "\n",
    "print(f'reference: {reference}')\n",
    "print(f'candidate: {candidate}')\n",
    "print(\"BLEU Score:\", bleu_score)\n",
    "print('\\n\\n')\n",
    "\n",
    "# Reference and candidate sentences as lists of words\n",
    "reference = ['the quick brown fox jumps over the lazy dog', 'the fast brown fox jumps over the lazy dog']\n",
    "candidate = 'the fast brown fox jumps over the lazy dog'\n",
    "\n",
    "# Calculate BLEU score\n",
    "bleu_score = sentence_bleu([r.split() for r in reference], candidate.split())\n",
    "\n",
    "print(f'references: {reference}')\n",
    "print(f'candidate: {candidate}')\n",
    "print(\"BLEU Score:\", bleu_score)\n",
    "print('\\n\\n')\n",
    "\n",
    "# Reference and candidate sentences as lists of words\n",
    "reference = ['the quick brown fox jumps over the lazy dog']\n",
    "candidate = 'the quick brown fox jumps over the dog'\n",
    "\n",
    "# Calculate BLEU score\n",
    "bleu_score = sentence_bleu([r.split() for r in reference], candidate.split())\n",
    "\n",
    "print(f'references: {reference}')\n",
    "print(f'candidate: {candidate}')\n",
    "print(\"BLEU Score:\", bleu_score)\n",
    "print('\\n\\n')\n",
    "\n",
    "# Reference and candidate sentences as lists of words\n",
    "reference = ['the quick brown fox jumps over the lazy dog']\n",
    "candidate = 'fox jumps over the dog'\n",
    "\n",
    "# Calculate BLEU score\n",
    "bleu_score = sentence_bleu([r.split() for r in reference], candidate.split())\n",
    "\n",
    "print(f'references: {reference}')\n",
    "print(f'candidate: {candidate}')\n",
    "print(\"BLEU Score:\", bleu_score)\n",
    "print('\\n\\n')\n",
    "\n",
    "# Reference and candidate sentences as lists of words\n",
    "reference = ['the quick brown fox jumps over the lazy dog']\n",
    "candidate = 'absolutely random sentence'\n",
    "\n",
    "# Calculate BLEU score\n",
    "bleu_score = sentence_bleu([r.split() for r in reference], candidate.split())\n",
    "\n",
    "print(f'references: {reference}')\n",
    "print(f'candidate: {candidate}')\n",
    "print(\"BLEU Score:\", bleu_score)\n",
    "print('\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='validation_strategies'></a>\n",
    "# 3. Validation Strategies\n",
    "\n",
    "<a id='overfitting'></a>\n",
    "## 3.1 Overfitting. Why do we need train/test concept? <br>\n",
    "\n",
    "We really don’t want to train and evaluate our model on the same dataset, since it would produce overfitting. In other words, we can’t tell whether the model simply memorized the training data or not, or whether it generalizes well to new, unseen data.\n",
    "\n",
    "Let's look at the problem in more detail using a simple toy example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "\n",
    "X_train = np.random.normal(0, 1, (500, 2))\n",
    "noise_train = np.random.normal(0, 1., 500)\n",
    "\n",
    "X_test = np.random.normal(0, 1, (100, 2))\n",
    "noise_test = np.random.normal(0, 1., 100)\n",
    "\n",
    "y_train = (np.sin(X_train) + np.cos(2*X_train)).sum(axis=1) + noise_train\n",
    "y_test = (np.sin(X_test) + np.cos(2*X_test)).sum(axis=1) + noise_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE on train: 2.046936920069584\n",
      "MSE on test: 1.8647307030508082\n"
     ]
    }
   ],
   "source": [
    "lr = Ridge(alpha=1.0, random_state=42)\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "y_train_preds = lr.predict(X_train)\n",
    "y_test_preds = lr.predict(X_test)\n",
    "\n",
    "print(f'MSE on train: {mean_squared_error(y_train, y_train_preds)}\\nMSE on test: {mean_squared_error(y_test, y_test_preds)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add some complexity (polynomial features) to the model and see what will happen with our metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "train_result = []\n",
    "test_result = []\n",
    "\n",
    "for pow_n in range(1, 10):\n",
    "    lr = Ridge(alpha=1.0, random_state=42)\n",
    "\n",
    "    X_train_poly = np.hstack([X_train**(p) for p in range(pow_n)])\n",
    "    X_test_poly = np.hstack([X_test**(p) for p in range(pow_n)])\n",
    "\n",
    "    lr.fit(X_train_poly, y_train)\n",
    "\n",
    "    y_train_preds = lr.predict(X_train_poly)\n",
    "    y_test_preds = lr.predict(X_test_poly)\n",
    "    \n",
    "    train_result.append(mean_squared_error(y_train, y_train_preds))\n",
    "    test_result.append(mean_squared_error(y_test, y_test_preds))\n",
    "    \n",
    "plt.plot(list(range(1, 10)), train_result, list(range(1, 10)), test_result)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion:\n",
    "- We almost always can reach optimal loss (in MSE case ~0) for the training set by adding nonlinear feature / stacking more layers to the model\n",
    "- We shouldn't stack layers and add features without proper control, because then we will get poor results in the real-life testing / competition leaderboard\n",
    "- So we need to somehow model real testing data using the only training dataset available\n",
    "\n",
    "![](https://preview.redd.it/n9fgba8b0qr01.png?auto=webp&s=e86d2d3447c777d3222016e81a0adfaec1a95592)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='holdout'></a>\n",
    "## 3.2 Holdout / Stratified split / train-validation-test <br>\n",
    "\n",
    "The holdout method is the simplest model evaluation technique. We take our labeled dataset and split it randomly into two parts: A **training set** and a **test set**:\n",
    "![](https://sebastianraschka.com/images/blog/2016/model-evaluation-selection-part1/testing_01.png)\n",
    "Then, we fit a model to the training data and predict the labels of the test set:\n",
    "![](https://sebastianraschka.com/images/blog/2016/model-evaluation-selection-part1/testing_02.png)\n",
    "And the fraction of correct predictions constitutes our estimate of the prediction accuracy.\n",
    "![](https://sebastianraschka.com/images/blog/2016/model-evaluation-selection-part1/testing_03.png)\n",
    "\n",
    "##### Pros:\n",
    "    + Simple\n",
    "    + Fast\n",
    "\n",
    "##### Cons:\n",
    "    - Not so precise estimate of out-of-sample performance comparing to more advanced techniques\n",
    "    \n",
    "### Class Balance\n",
    "\n",
    "As it was said, you want your validation to mimic your test set as close as possible. And you can make a fair assumprion (that is not always true), that distribution of target on train and not seen data is the same. Then you have to use stratification. Stratification ensures stable distributions across split. That is more than just useful if:\n",
    "\n",
    "    + Dataset is small\n",
    "    + Dataset is unbalanced (average target close to 0 or to 1)\n",
    "    + You have multiclassification task\n",
    "    \n",
    "    \n",
    "### Model Checkpoint Selection\n",
    "\n",
    "If we consider gradient-based training of models, for example neural networks or gradient boosting, then as a result of each epoch there will be some new model weights. Thus, the model at different epochs will behave differently on previously unseen data, so it is logical for the best result to choose a checkpoint from the epoch at which the target metric has the best values on previously unseen data.\n",
    "\n",
    "However, by selecting the weights of the model in this way, we can also get some kind of overfit, since we choose these weights as the best according to the validation dataset, it is quite obvious that on average on any other previously unseen dataset the results of our model in terms of metrics will be worse.\n",
    "\n",
    "Thus, in order to correctly select a model checkpoint after optimization or implement early stopping and also correctly estimate the results of the model on previously unseen data, we can apply train/validation/test strategy.\n",
    "\n",
    "![](https://editor.analyticsvidhya.com/uploads/18265Screenshot-from-2020-10-06-16-35-50-768x432.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.43253893788703324, 0.42294220665499127)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#straightforward train/test split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df_twitter.text, df_twitter.target, test_size=0.3, random_state=42\n",
    ")\n",
    "y_train.mean(), y_test.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.429724150872584, 0.4295096322241681)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#stratified train/test split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df_twitter.text, df_twitter.target, test_size=0.3, random_state=42, stratify=df_twitter.target\n",
    ")\n",
    "y_train.mean(), y_test.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='kfold'></a>\n",
    "## 3.3 K-fold / Stratified K-fold / Repeated K-fold\n",
    "\n",
    "**K-fold Cross-validation** is probably the most common technique for model evaluation and model selection. \n",
    "- We split the dataset into *K* parts and iterate over a dataset set *K* times\n",
    "- In each round one part is used for validation, and the remaining *K-1* parts are merged into a training subset for model evaluation\n",
    "- We compute the cross-validation performance as the arithmetic mean over the *K* performance estimates from the validation sets.\n",
    "![](https://sebastianraschka.com/images/blog/2016/model-evaluation-selection-part3/kfold.png)\n",
    "\n",
    "\n",
    "**Stratified K-fold Cross-validation** - we use k-fold as described above, but we will use stratification by target on each split. <br>\n",
    "\n",
    "**Repeated K-fold Cross-validation** - we use k-fold as described above, but we will run the whole process n times with different randomizations durig split. This strategy could be useful if we have a small dataset available and the metric varies significantly from fold to fold.<br>\n",
    "\n",
    "##### Pros:\n",
    "    + Better estimate of out-of-sample performance than simple train/test split\n",
    "\n",
    "##### Cons:\n",
    "    - Runs \"K\" times slower than simple train/test split\n",
    "\n",
    "If we have **little data** and **enough time**, it's better to always do cross-validation for a more precise estimate of performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Holdout result:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8605527274547953"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#stratified train/test split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df_twitter.text, df_twitter.target, test_size=0.3, random_state=42, stratify=df_twitter.target\n",
    ")\n",
    "y_train.mean(), y_test.mean()\n",
    "\n",
    "\n",
    "print('Holdout result:')\n",
    "pipe_classification.fit(X_train, y_train)\n",
    "roc_auc_score(y_test, pipe_classification.predict_proba(X_test)[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.86635822 0.85548835 0.8611068  0.84779505 0.84860123 0.86266664\n",
      " 0.85761553]\n",
      "Mean: 0.8571\n",
      "Std: 0.0065\n",
      "3 std range: [0.8376, 0.8765]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "\n",
    "cv = StratifiedKFold(n_splits=7, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform cross-validation and calculate AUC scores for each fold\n",
    "auc_scores = cross_val_score(pipe_classification, df_twitter.text, df_twitter.target, cv=cv, scoring='roc_auc')\n",
    "print(auc_scores)\n",
    "print(f'Mean: {round(auc_scores.mean(), 4)}')\n",
    "print(f'Std: {round(auc_scores.std(), 4)}')\n",
    "print(f'3 std range: [{round(auc_scores.mean() - 3*auc_scores.std(), 4)}, {round(auc_scores.mean() + 3*auc_scores.std(), 4)}]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='timebased'></a>\n",
    "## Time-based validation / Time K-fold\n",
    "\n",
    "Doing **Time validation** in correct way is very important. Suppose you have a task to predict Wikipedia page viewers as in on of previous Kaggle competitions (https://www.kaggle.com/c/web-traffic-time-series-forecasting). What are possible ways to do a validation? Again, it is best to mimic split made by organizers and they split this by date. All before January, 1st, 2017 went to train, all after that date (2 months) - to test. The correct way to perform a split is with **sliding window**:\n",
    " \n",
    "\n",
    "![](http://eng.uber.com/wp-content/uploads/2018/01/image3-4.png)\n",
    "\n",
    "Another possible option is to add as much train data from the past as possible on each fold:\n",
    "![](https://miro.medium.com/v2/resize:fit:1204/1*qvdnPF8ETV9mFdMT0Y_BBA.png)\n",
    "\n",
    "In NLP, such a split is not very common, but in some cases it can be used if there is a clear bias in the texts that is caused by time. For example, the topic of news and articles in different social media websites changes over time, or over long periods in fiction books the vocabulary and grammar of the language itself changes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='groupkfold'></a>\n",
    "## 3.5 Group K-fold <br>\n",
    "\n",
    "- The dataset is divided into k folds, just like traditional k-fold cross-validation.\n",
    "- Instead of random assignment to folds, GroupKFold ensures that all data points with the same group label (or identifier) are placed in the same fold.\n",
    "- During each iteration of cross-validation, one of the k folds is used as the test set, while the remaining k-1 folds are used as the training set. Importantly, data points with the same group label are kept together in either the training set or the test set.\n",
    "- The cross-validation process is repeated k times, with each of the k folds serving as the test set exactly once.\n",
    "\n",
    "Group K-fold plays a very important role in NLP, there are several task examples:\n",
    "- Authorship Attribution: you may have a dataset of texts written by various authors. You want to evaluate a machine learning model's ability to predict the correct author of a text or to have ability to predict different text attributes or properties for previously unseen authors. To avoid data leakage, you can use GroupKFold with author IDs as the grouping variable. This ensures that all texts from the same author are in the same fold during cross-validation.\n",
    "- Sentiment Analysis: In sentiment analysis tasks, where you classify text based on sentiment (e.g., positive, negative, neutral), you might have reviews or comments grouped by products, movies, or topics. GroupKFold helps ensure that all reviews for a specific product or movie are together in one fold during cross-validation.\n",
    "- Topic Modeling: In topic modeling tasks, where you aim to discover latent topics within a collection of documents, you can use GroupKFold to group documents by source or domain, ensuring that all documents from the same source are in the same fold during cross-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='validation_mismatch'></a>\n",
    "# 4. Local validation VS real-life / competition testing metrics mismatch <br>\n",
    "\n",
    "Sometimes there are situations when your evaluation metrics in your local validation differ significantly from the actual metrics in production or in the competition test dataset. \n",
    "\n",
    "There are several aspects of the problem:\n",
    "\n",
    "<a id='wrong_local_validation'></a>\n",
    "# 4.1 Wrong local validation strategy \n",
    "- There is a significant time component in your data and you don't use time-based split\n",
    "- The group-split strategy is needed and you missed it\n",
    "- A more advanced combination of time and group split is needed\n",
    "- If there is a huge gap between validation and real-life/lb, while train and val scores are similar - you certainly have a data leak. Carefuly review your EDA. Try to remove most predictive features and compare the results.\n",
    "- Consider different metrics, so maybe it will give you an idea of what is going on (roc-auc/pr-auc example)\n",
    "\n",
    "**Try to reproduce validation split that is relevant to a real life scenarios at all costs.**\n",
    "\n",
    "<a id='shifted_features'></a>\n",
    "# 4.2 Shifted features distributions\n",
    "\n",
    "Another common problem - natural features distributions shift.\n",
    "- The most common cases happen in analysis financial markets: the distribution of stock prices, trading volumes, or volatility can change due to market conditions or economic events.\n",
    "- Another popular case is recommender systems, becaus user preferences or behaviors in recommender systems may evolve, leading to shifts in the distribution of user interaction data.\n",
    "- There are also some cases in NLP, e.g. in sentiment analysis, language style, topics, or writing conventions may change over time, causing shifts in the distribution of text data.\n",
    "- And the last but not the least: such problems can be caused by errors and bugs in your data collection and processing pipelines and it could turn out that train, test and real-life online data are actually collected in a slightly different ways under the hood."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's replicate toy example with feature collection bug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_available_train, df_unseen_test = train_test_split(\n",
    "    df_twitter, stratify=df_twitter.target, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    df_available_train.text, df_available_train.target, stratify=df_available_train.target, test_size=0.3, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8459589430271457"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_classification.fit(X_train, y_train)\n",
    "\n",
    "proba = pipe_classification.predict_proba(X_val)[:, 1]\n",
    "roc_auc_score(y_val, proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8525147409373648"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proba = pipe_classification.predict_proba(df_unseen_test.text)[:, 1]\n",
    "roc_auc_score(df_unseen_test.target, proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, in a normal scenario there is no huge difference betweeen \"local\" and \"unseen data\" validation.\n",
    "\n",
    "Let's replicate bug in which we lose some parts of input text in the \"unseen data\".\n",
    "With this \"bug\" we have a ~5% drop in roc-auc metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8034317418519012"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def string_rand_filtering(text, ratio_drop=0.5):\n",
    "    words = text.split()\n",
    "    num_words_to_delete = int(ratio_drop * len(words))\n",
    "    words_to_delete = random.sample(words, num_words_to_delete)\n",
    "    modified_text = ' '.join(word for word in words if word not in words_to_delete)\n",
    "    return modified_text\n",
    "\n",
    "df_unseen_test_corrupted = df_unseen_test.copy()\n",
    "df_unseen_test_corrupted.text = df_unseen_test_corrupted.text.apply(string_rand_filtering)\n",
    "\n",
    "proba = pipe_classification.predict_proba(df_unseen_test_corrupted.text)[:, 1]\n",
    "roc_auc_score(df_unseen_test_corrupted.target, proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is there a way to detect that something is wrong with the test data in terms of features distribution in a semi-automated way? - **Yes!**\n",
    "\n",
    "<a id='adversarial_validation'></a>\n",
    "# 4.3 Adversarial validation\n",
    "\n",
    "The general idea is to check the degree of similarity between training and tests in terms of feature distribution: if they are difficult to distinguish, the distribution is probably similar and the usual validation techniques should work.\n",
    "If it does not seem to be the case, so we can suspect they are quite different. This intuition can be quantified by combining train and test sets, assigning 0/1 labels (0 — train, 1-test), and evaluating a binary classification task. For adversarial validation, we want to create a model that predicts which rows are in the training dataset, and which are in the test set. We, therefore, create a new target column in which the test samples are labeled 1 and the train samples with 0. <br>\n",
    "\n",
    "**Note:** The Performance of this model will be indicator of how big the problem is. In order to make it work we need to use the model of the same complexity for both the main problem and adversarial validation problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5035948562742225"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_adversarial = pd.concat([df_available_train, df_unseen_test]).reset_index()\n",
    "df_adversarial.target = len(df_available_train)*[0] + len(df_unseen_test)*[1]\n",
    "\n",
    "X_train_adv, X_val_adv, y_train_adv, y_val_adv = train_test_split(\n",
    "    df_adversarial.text, df_adversarial.target, stratify=df_adversarial.target, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "pipe_classification.fit(X_train_adv, y_train_adv)\n",
    "\n",
    "proba = pipe_classification.predict_proba(X_val_adv)[:, 1]\n",
    "roc_auc_score(y_val_adv, proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adversarial validation for the initial complete test dataset - ROCAUC=0.5 means that it's impossible to tell whether this particular sample is from the train set or from the unseen test, so we don't have any significant features distributions shift."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6809575327645472"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_adversarial = pd.concat([df_available_train, df_unseen_test_corrupted]).reset_index()\n",
    "df_adversarial.target = len(df_available_train)*[0] + len(df_unseen_test_corrupted)*[1]\n",
    "\n",
    "X_train_adv, X_val_adv, y_train_adv, y_val_adv = train_test_split(\n",
    "    df_adversarial.text, df_adversarial.target, stratify=df_adversarial.target, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "pipe_classification.fit(X_train_adv, y_train_adv)\n",
    "\n",
    "proba = pipe_classification.predict_proba(X_val_adv)[:, 1]\n",
    "roc_auc_score(y_val_adv, proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adversarial validation for the corrupted test dataset - ROCAUC=0.68 means that in many cases we can tell whether this particular sample is from the train set or from the unseen test, so we obviously have a features distributions shift."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Homework'></a>\n",
    "# Homework\n",
    "\n",
    "Theory:\n",
    "- Read and analyze equations and implementations of multiclass extensions of classification metrics: precision, recall, f1, micro/macro averaging\n",
    "- For a task similar to the one proposed above (commonlit-evaluate-student-summaries) regression for both targets with the same input tables structure. Propose and describe in writing validation schemes in such cases:\n",
    "    - Case in which we want to evaluate other students on the same questions (promt text + promt question)\n",
    "    - Case in which we want to evaluate the same students on different (unseen) questions (promt text + promt question)\n",
    "    - Case in which we want to evaluate other (unseen) students on different (unseen) questions (promt text + promt question)\n",
    "\n",
    "\n",
    "Practice:\n",
    "- For a task similar to the one proposed above (commonlit-evaluate-student-summaries) regression for both targets with the same input tables structure. Propose and implement in python validation (with simple modeling) assuming that we want to evaluate the same students on different (unseen) questions (promt text + promt question). Modeling itself is not the case here, What is more important here is the implementation of the validation mechanics."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
